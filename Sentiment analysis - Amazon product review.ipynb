{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Import Libraries"
      ],
      "metadata": {
        "id": "tuoxdytC6ITE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "SR9278KvT6s0"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Sequential\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.layers import Dense,Flatten,LSTM,Dropout,Embedding\n",
        "from tensorflow.keras.utils import pad_sequences"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exctract review text and save as csv files"
      ],
      "metadata": {
        "id": "6Qwx00UM5piG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tQWgDaircQYh"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "with open('/content/drive/MyDrive/domain_sentiment_data/sorted_data_acl/books/positive.review', 'r') as file:\n",
        "    content = file.read()\n",
        "    start_tag = '<review_text>'\n",
        "    end_tag = '</review_text>'\n",
        "    csv_file = open('book_positive.csv', 'w', newline='', encoding='utf-8')\n",
        "    csv_writer = csv.writer(csv_file)\n",
        "    csv_writer.writerow(['Review Text'])\n",
        "    start_index = 0\n",
        "    while True:\n",
        "        start_index = content.find(start_tag, start_index)\n",
        "        if start_index == -1:\n",
        "            break\n",
        "        start_index += len(start_tag)\n",
        "        end_index = content.find(end_tag, start_index)\n",
        "        review_text = content[start_index:end_index].strip()\n",
        "        csv_writer.writerow([review_text])\n",
        "    csv_file.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7CCgC6_pfxbT"
      },
      "outputs": [],
      "source": [
        "with open('/content/drive/MyDrive/domain_sentiment_data/sorted_data_acl/books/negative.review', 'r') as file:\n",
        "    content = file.read()\n",
        "    start_tag = '<review_text>'\n",
        "    end_tag = '</review_text>'\n",
        "    csv_file = open('book_negative.csv', 'w', newline='', encoding='utf-8')\n",
        "    csv_writer = csv.writer(csv_file)\n",
        "    csv_writer.writerow(['Review Text'])\n",
        "    start_index = 0\n",
        "    while True:\n",
        "        start_index = content.find(start_tag, start_index)\n",
        "        if start_index == -1:\n",
        "            break\n",
        "        start_index += len(start_tag)\n",
        "        end_index = content.find(end_tag, start_index)\n",
        "        review_text = content[start_index:end_index].strip()\n",
        "        csv_writer.writerow([review_text])\n",
        "    csv_file.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GwPPxw6cf_Gf"
      },
      "outputs": [],
      "source": [
        "with open('/content/drive/MyDrive/domain_sentiment_data/sorted_data_acl/dvd/positive.review', 'r') as file:\n",
        "    content = file.read()\n",
        "    start_tag = '<review_text>'\n",
        "    end_tag = '</review_text>'\n",
        "    csv_file = open('dvd_positive.csv', 'w', newline='', encoding='utf-8')\n",
        "    csv_writer = csv.writer(csv_file)\n",
        "    csv_writer.writerow(['Review Text'])\n",
        "    start_index = 0\n",
        "    while True:\n",
        "        start_index = content.find(start_tag, start_index)\n",
        "        if start_index == -1:\n",
        "            break\n",
        "        start_index += len(start_tag)\n",
        "        end_index = content.find(end_tag, start_index)\n",
        "        review_text = content[start_index:end_index].strip()\n",
        "        csv_writer.writerow([review_text])\n",
        "    csv_file.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VsQsmmN_f_0n"
      },
      "outputs": [],
      "source": [
        "with open('/content/drive/MyDrive/domain_sentiment_data/sorted_data_acl/dvd/negative.review', 'r') as file:\n",
        "    content = file.read()\n",
        "    start_tag = '<review_text>'\n",
        "    end_tag = '</review_text>'\n",
        "    csv_file = open('dvd_negative.csv', 'w', newline='', encoding='utf-8')\n",
        "    csv_writer = csv.writer(csv_file)\n",
        "    csv_writer.writerow(['Review Text'])\n",
        "    start_index = 0\n",
        "    while True:\n",
        "        start_index = content.find(start_tag, start_index)\n",
        "        if start_index == -1:\n",
        "            break\n",
        "        start_index += len(start_tag)\n",
        "        end_index = content.find(end_tag, start_index)\n",
        "        review_text = content[start_index:end_index].strip()\n",
        "        csv_writer.writerow([review_text])\n",
        "    csv_file.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2avf5nOmgAg-"
      },
      "outputs": [],
      "source": [
        "with open('/content/drive/MyDrive/domain_sentiment_data/sorted_data_acl/electronics/positive.review', 'r') as file:\n",
        "    content = file.read()\n",
        "    start_tag = '<review_text>'\n",
        "    end_tag = '</review_text>'\n",
        "    csv_file = open('electronics_positive.csv', 'w', newline='', encoding='utf-8')\n",
        "    csv_writer = csv.writer(csv_file)\n",
        "    csv_writer.writerow(['Review Text'])\n",
        "    start_index = 0\n",
        "    while True:\n",
        "        start_index = content.find(start_tag, start_index)\n",
        "        if start_index == -1:\n",
        "            break\n",
        "        start_index += len(start_tag)\n",
        "        end_index = content.find(end_tag, start_index)\n",
        "        review_text = content[start_index:end_index].strip()\n",
        "        csv_writer.writerow([review_text])\n",
        "    csv_file.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zsxQqT93gBFk"
      },
      "outputs": [],
      "source": [
        "with open('/content/drive/MyDrive/domain_sentiment_data/sorted_data_acl/electronics/negative.review', 'r') as file:\n",
        "    content = file.read()\n",
        "    start_tag = '<review_text>'\n",
        "    end_tag = '</review_text>'\n",
        "    csv_file = open('electronics_negative.csv', 'w', newline='', encoding='utf-8')\n",
        "    csv_writer = csv.writer(csv_file)\n",
        "    csv_writer.writerow(['Review Text'])\n",
        "    start_index = 0\n",
        "    while True:\n",
        "        start_index = content.find(start_tag, start_index)\n",
        "        if start_index == -1:\n",
        "            break\n",
        "        start_index += len(start_tag)\n",
        "        end_index = content.find(end_tag, start_index)\n",
        "        review_text = content[start_index:end_index].strip()\n",
        "        csv_writer.writerow([review_text])\n",
        "    csv_file.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4h5j7oD-gg6I"
      },
      "outputs": [],
      "source": [
        "with open('/content/drive/MyDrive/domain_sentiment_data/sorted_data_acl/kitchen_&_housewares/positive.review', 'r') as file:\n",
        "    content = file.read()\n",
        "    start_tag = '<review_text>'\n",
        "    end_tag = '</review_text>'\n",
        "    csv_file = open('kitchen_positive.csv', 'w', newline='', encoding='utf-8')\n",
        "    csv_writer = csv.writer(csv_file)\n",
        "    csv_writer.writerow(['Review Text'])\n",
        "    start_index = 0\n",
        "    while True:\n",
        "        start_index = content.find(start_tag, start_index)\n",
        "        if start_index == -1:\n",
        "            break\n",
        "        start_index += len(start_tag)\n",
        "        end_index = content.find(end_tag, start_index)\n",
        "        review_text = content[start_index:end_index].strip()\n",
        "        csv_writer.writerow([review_text])\n",
        "    csv_file.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iCIEAh66giVW"
      },
      "outputs": [],
      "source": [
        "with open('/content/drive/MyDrive/domain_sentiment_data/sorted_data_acl/kitchen_&_housewares/negative.review', 'r') as file:\n",
        "    content = file.read()\n",
        "    start_tag = '<review_text>'\n",
        "    end_tag = '</review_text>'\n",
        "    csv_file = open('kitchen_negative.csv', 'w', newline='', encoding='utf-8')\n",
        "    csv_writer = csv.writer(csv_file)\n",
        "    csv_writer.writerow(['Review Text'])\n",
        "    start_index = 0\n",
        "    while True:\n",
        "        start_index = content.find(start_tag, start_index)\n",
        "        if start_index == -1:\n",
        "            break\n",
        "        start_index += len(start_tag)\n",
        "        end_index = content.find(end_tag, start_index)\n",
        "        review_text = content[start_index:end_index].strip()\n",
        "        csv_writer.writerow([review_text])\n",
        "    csv_file.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yC8_4qeDdpUz",
        "outputId": "148935a6-7810-4be5-ebab-c7ff0515d939"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wrRCH_VhcR6H"
      },
      "outputs": [],
      "source": [
        "book_p = pd.read_csv(\"/content/book_positive.csv\")\n",
        "book_n = pd.read_csv(\"/content/dvd_negative.csv\")\n",
        "dvd_p  = pd.read_csv(\"/content/dvd_positive.csv\")\n",
        "dvd_n  = pd.read_csv(\"/content/dvd_negative.csv\")\n",
        "ele_p  = pd.read_csv(\"/content/electronics_positive.csv\")\n",
        "ele_n  = pd.read_csv(\"/content/electronics_negative.csv\")\n",
        "kit_p  = pd.read_csv(\"/content/kitchen_positive.csv\")\n",
        "kit_n  = pd.read_csv(\"/content/kitchen_negative.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5OJ0NhMtddoN"
      },
      "outputs": [],
      "source": [
        "positive = pd.concat([book_p,dvd_p,ele_p,kit_p],axis = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SwSSUGQFev5P"
      },
      "outputs": [],
      "source": [
        "positive[\"Label\"] = [1]*len(positive)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M_sx7A9dfF0m"
      },
      "outputs": [],
      "source": [
        "#positive.to_csv(\"positive.csv\",index = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OJG_uhzVdz0K"
      },
      "outputs": [],
      "source": [
        "negative = pd.concat([book_n,dvd_n,ele_n,kit_n],axis = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m98Fg8iDff59"
      },
      "outputs": [],
      "source": [
        "negative[\"Label\"] = [0]*len(negative)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4w0VQAwWfq8m"
      },
      "outputs": [],
      "source": [
        "#negative.to_csv(\"negative.csv\",index = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jWPC6kVvgVfb"
      },
      "outputs": [],
      "source": [
        "review_dataset = pd.concat([positive,negative],axis = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NAhvn6tgg0pV"
      },
      "outputs": [],
      "source": [
        "#review_dataset.to_csv(\"review_dataset.csv\",index = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d5rv2-DAk3kn"
      },
      "outputs": [],
      "source": [
        "review_dataset = review_dataset.reset_index(drop = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sp_IvzjXlDW3"
      },
      "outputs": [],
      "source": [
        "review_dataset.to_pickle(\"combined_review.pkl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##model using Spacy and Gensim"
      ],
      "metadata": {
        "id": "Mdu08nIeXaul"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!spacy download en_core_web_lg"
      ],
      "metadata": {
        "id": "GH2GIH_UXguG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy"
      ],
      "metadata": {
        "id": "7O4sdVPlXmvS"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"en_core_web_lg\")"
      ],
      "metadata": {
        "id": "QAYZGSIfX_x3"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.downloader as api"
      ],
      "metadata": {
        "id": "oN-CSP1fYI3m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wv = api.load(\"word2vec-google-news-300\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-BkoOkuZUvZ",
        "outputId": "e3b32f9c-6125-49b9-8a23-e6cdd3519560"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[=================================================-] 99.9% 1661.8/1662.8MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def data_loader(file_path):\n",
        "  data = pd.read_pickle(file_path)\n",
        "  return data"
      ],
      "metadata": {
        "id": "h1e74DYpcUIU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "review = data_loader(\"/content/combined_review.pkl\")"
      ],
      "metadata": {
        "id": "y6DIDrqFcU0u"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "review = data_loader(\"/content/combined_review.pkl\")"
      ],
      "metadata": {
        "id": "5mlSh0kXcIS8"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "review = pd.read_pickle(\"/content/combined_review.pkl\")"
      ],
      "metadata": {
        "id": "rbAkB4nTcLgk"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def word_preprocessing(text):\n",
        "  doc = nlp(text)\n",
        "  tokens = []\n",
        "  for token in doc:\n",
        "    if token.is_punct or token.is_stop:\n",
        "      continue\n",
        "    tokens.append(token.lemma_)\n",
        "  return wv.get_mean_vector(tokens)"
      ],
      "metadata": {
        "id": "tbBNggv4Z3bc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "review[\"word_to_vec\"] = review[\"Review Text\"].apply(lambda text:word_preprocessing(text))"
      ],
      "metadata": {
        "id": "QarfbBTebvue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "review.to_pickle(\"vector_data.pkl\")"
      ],
      "metadata": {
        "id": "unjy5DoWcpLn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "review = pd.read_pickle(\"/content/vector_data.pkl\")"
      ],
      "metadata": {
        "id": "SgDwSU57in3J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = review.word_to_vec.values\n",
        "y = review.Label"
      ],
      "metadata": {
        "id": "g-j3WhpaeJ0M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_flatten = np.stack(X)"
      ],
      "metadata": {
        "id": "MMbJhzWRhW9L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train,x_test,y_train,y_test = train_test_split(x_flatten,y,test_size = 0.2,stratify = y,random_state = 42 )"
      ],
      "metadata": {
        "id": "VT2gSxjOgF3r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ps7HEulXg-Rc",
        "outputId": "63ac2d91-b7da-4427-8149-2a7c82824d27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6400, 300)"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spacy_model = keras.Sequential([\n",
        "    #keras.layers.Flatten(),\n",
        "    keras.layers.Dense(128,activation = \"relu\"),\n",
        "    keras.layers.Dense(64,activation =  \"relu\"),\n",
        "    keras.layers.Dense(32,activation = \"relu\"),\n",
        "    keras.layers.Dense(1,activation = \"sigmoid\")\n",
        "])"
      ],
      "metadata": {
        "id": "pX6opOo7gHiP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spacy_model.compile(\n",
        "    optimizer = \"rmsprop\",\n",
        "    loss = \"binary_crossentropy\",\n",
        "    metrics = [\"accuracy\"]\n",
        ")"
      ],
      "metadata": {
        "id": "cU6z6JkDgqYP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spacy_model.fit(x_train,y_train,epochs = 10,validation_data = (x_test,y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xDRF7_6_gvj3",
        "outputId": "b612b1b3-cb79-4552-a6bd-941d44c3306b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "200/200 [==============================] - 2s 4ms/step - loss: 0.5690 - accuracy: 0.7098 - val_loss: 0.4521 - val_accuracy: 0.8019\n",
            "Epoch 2/10\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.4458 - accuracy: 0.7911 - val_loss: 0.4701 - val_accuracy: 0.7756\n",
            "Epoch 3/10\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.4214 - accuracy: 0.8080 - val_loss: 0.4209 - val_accuracy: 0.8025\n",
            "Epoch 4/10\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.4038 - accuracy: 0.8152 - val_loss: 0.4024 - val_accuracy: 0.8169\n",
            "Epoch 5/10\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.3957 - accuracy: 0.8188 - val_loss: 0.4015 - val_accuracy: 0.8231\n",
            "Epoch 6/10\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.3780 - accuracy: 0.8295 - val_loss: 0.3915 - val_accuracy: 0.8206\n",
            "Epoch 7/10\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.3662 - accuracy: 0.8320 - val_loss: 0.3794 - val_accuracy: 0.8300\n",
            "Epoch 8/10\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.3540 - accuracy: 0.8428 - val_loss: 0.3808 - val_accuracy: 0.8244\n",
            "Epoch 9/10\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.3375 - accuracy: 0.8516 - val_loss: 0.3678 - val_accuracy: 0.8431\n",
            "Epoch 10/10\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.3202 - accuracy: 0.8578 - val_loss: 0.3632 - val_accuracy: 0.8388\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6c1668fdc0>"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "file = \"spacy_model.pkl\"\n",
        "with open(file,\"wb\") as f:\n",
        "  pickle.dump(spacy_model,f)"
      ],
      "metadata": {
        "id": "GY14aQaFmfk2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spacy_model.save(\"/content/spacy_model.h5\")"
      ],
      "metadata": {
        "id": "4xL6HPL7nA0t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LSTM model"
      ],
      "metadata": {
        "id": "eCAJGe18vgpn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def word_tokenizer(text):\n",
        "  doc = nlp(text)\n",
        "  tokens = []\n",
        "  for token in doc:\n",
        "    if token.is_punct or token.is_stop:\n",
        "      continue\n",
        "    tokens.append(token.lemma_)\n",
        "  return tokens"
      ],
      "metadata": {
        "id": "-UuQhLY6oL93"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "review[\"preprocessed_text\"] = review[\"Review Text\"].apply(lambda text:word_tokenizer(text))"
      ],
      "metadata": {
        "id": "c4d31TwMoX0r"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "WQtBHQAknyD4"
      },
      "outputs": [],
      "source": [
        "X = review[\"preprocessed_text\"]\n",
        "y = review[\"Label\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "wzSLxCw9oOvS"
      },
      "outputs": [],
      "source": [
        "x_train,x_test,y_train,y_test = train_test_split(X,y,test_size = 0.2,stratify = y,random_state = 42 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "NqEActnNfvKL"
      },
      "outputs": [],
      "source": [
        "token = Tokenizer(num_words = 1000)\n",
        "token.fit_on_texts(x_train)\n",
        "sequences_train = token.texts_to_sequences(x_train)\n",
        "sequs_matrics_train = pad_sequences(sequences_train,maxlen = 1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "o4A4UpTggElT"
      },
      "outputs": [],
      "source": [
        "sequences_test = token.texts_to_sequences(x_test)\n",
        "sequs_matrics_test = pad_sequences(sequences_test,maxlen = 1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "zJep2Fmh3Uc5"
      },
      "outputs": [],
      "source": [
        "model = keras.Sequential([\n",
        "    keras.layers.Input(shape = [1000]),\n",
        "    keras.layers.Embedding(1000,50),\n",
        "    keras.layers.LSTM(64),\n",
        "    keras.layers.Dense(50,activation = \"relu\"),\n",
        "    keras.layers.Dense(1,activation = \"sigmoid\")\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "fMPBF6VJ3XkY"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    optimizer = \"rmsprop\",\n",
        "    loss = \"binary_crossentropy\",\n",
        "    metrics = [\"accuracy\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19Bl6CnZouWd",
        "outputId": "f64d256c-1dc4-46f3-8ce8-a8ad04c018c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "200/200 [==============================] - 107s 523ms/step - loss: 0.5557 - accuracy: 0.7027 - val_loss: 0.4356 - val_accuracy: 0.7969\n",
            "Epoch 2/5\n",
            "200/200 [==============================] - 103s 514ms/step - loss: 0.3853 - accuracy: 0.8322 - val_loss: 0.4195 - val_accuracy: 0.8006\n",
            "Epoch 3/5\n",
            "200/200 [==============================] - 97s 484ms/step - loss: 0.3472 - accuracy: 0.8503 - val_loss: 0.3955 - val_accuracy: 0.8206\n",
            "Epoch 4/5\n",
            "200/200 [==============================] - 95s 476ms/step - loss: 0.3171 - accuracy: 0.8670 - val_loss: 0.3989 - val_accuracy: 0.8238\n",
            "Epoch 5/5\n",
            "200/200 [==============================] - 95s 478ms/step - loss: 0.2935 - accuracy: 0.8800 - val_loss: 0.3895 - val_accuracy: 0.8200\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb367debb20>"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ],
      "source": [
        "model.fit(sequs_matrics_train,y_train,epochs = 5,validation_data = (sequs_matrics_test,y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create the model as pickle file"
      ],
      "metadata": {
        "id": "Zgixcix58dxk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle"
      ],
      "metadata": {
        "id": "PA6BFvlnqT_e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_file = \"model.pkl\"\n",
        "with open(model_file,\"wb\") as f:\n",
        "  pickle.dump(model,f)"
      ],
      "metadata": {
        "id": "4Av3wT5eqV1w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer_file = \"token.pkl\"\n",
        "with open(tokenizer_file,\"wb\") as file:\n",
        "  pickle.dump(token,file)"
      ],
      "metadata": {
        "id": "2pIi2s2BYukl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"/content/model.h5\")"
      ],
      "metadata": {
        "id": "WbAGID5toq-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Make predictions"
      ],
      "metadata": {
        "id": "7cg4tsAa8s7c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Sphere by Michael Crichton is an excellant novel. This was certainly the hardest to put down of all of the Crichton novels that I have read. \\n\\nThe story revolves around a man named Norman Johnson. Johnson is a phycologist. He travels with 4 other civilans to a remote location in the Pacific Ocean to help the Navy in a top secret misssion. They quickly learn that under the ocean is a half mile long spaceship. The civilans travel to a center 1000 feet under the ocean to live while researching the spacecraft. They are joined by 5 Navy personel to help them run operations. However on the surface a typhoon comes and the support ships on the surface must leave. The team of ten is stuck 1000 feet under the surface of the ocean. After a day under the sea they find out that the spacecraft is actually an American ship that has explored black holes and has brought back some strange things back to earth.\\n\\nThis novel does not have the research that some of the other Crichton novels have, but it still has a lot of information on random things from the lawes of partial pressure to behavior analysis.\\n\\nI would strongly recommend this book\""
      ],
      "metadata": {
        "id": "nxfehEqUxeLY"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = word_tokenizer(text)\n",
        "sequences_test = token.texts_to_sequences(tokens)\n",
        "processed_text = pad_sequences(sequences_test,maxlen = 1000) "
      ],
      "metadata": {
        "id": "G_7iRcmGf4em"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_class = \"positive\" if model.predict(processed_text)[0][0]>0.5 else \"negative\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2l5hEUNo0SzB",
        "outputId": "043aa5da-dc08-41d1-cb73-15a6b214b295"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 89ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_class"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "L9Yz_boXwDgq",
        "outputId": "bf8ccc1a-577d-4013-dad2-3c72d21b93dc"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'negative'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Validation UI"
      ],
      "metadata": {
        "id": "aSn4R2qJwRem"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.load_model(\"/content/model.h5\")"
      ],
      "metadata": {
        "id": "LB3OBYVcMTir"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer_file = \"/content/token.pkl\"\n",
        "with open(tokenizer_file, \"rb\") as f:\n",
        "    tokenizer = pickle.load(f)"
      ],
      "metadata": {
        "id": "BjIfe6RtLl31"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = input(\"Enter your text: \")\n",
        "tokens = word_tokenizer(text)\n",
        "sequences_test = tokenizer.texts_to_sequences(tokens)\n",
        "processed_text = pad_sequences(sequences_test,maxlen = 1000)\n",
        "\n",
        "predicted_class = \"positive\" if model.predict(processed_text)[0][0]>0.5 else \"negative\"\n",
        "print(\"This review sentence is:\", predicted_class)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3zlWpywBwWi-",
        "outputId": "33d5d584-2bdb-46de-b8aa-d3c1f9c65921"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your text: this is bad\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "This review sentence is: negative\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "tuoxdytC6ITE",
        "6Qwx00UM5piG"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}